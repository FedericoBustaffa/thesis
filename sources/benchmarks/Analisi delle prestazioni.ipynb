{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Struttura dei test\n",
    "\n",
    "Di seguito un'analisi sulle performance del modulo implementato (PPGA). Andremo\n",
    "quindi a confrontare:\n",
    "\n",
    "- Versione sequenziale e versione parallela di PPGA.\n",
    "- Confronto tra PPGA e DEAP (sequenziale e parallelo).\n",
    "- Considerazioni finali sul problema specifico del paper per un corretto\n",
    "  utilizzo della versione parallela ed evitare comportamenti inattesi.\n",
    "\n",
    "I benchmark sono stati effettuati su una macchina con doppio processore AMD\n",
    "EPYC 7313, ciascuno dei quali a 16 core con frequenza di clock massima a 3.7\n",
    "GHz. Il problema di riferimento è quello di explainability in cui è stato\n",
    "eseguito l'algoritmo genetico su un solo punto del dataset (32 features) e su\n",
    "una sola classe target. I parametri presi in considerazione sono:\n",
    "\n",
    "- **Modello di ML**: RandomForestClassifier, SVC e MLPClassifier.\n",
    "- **Numero di individui sintetici**: 1000, 2000, 4000, 8000, 16000.\n",
    "- **Numero di worker**: 1, 2, 4, 8, 16, 32. Le esecuzioni con 1 worker\n",
    "  corrispondono in realtà alla versione sequenziale dell'algoritmo.\n",
    "\n",
    "Sono state esplorate tutte le possibili combinazioni di tali parametri e, per\n",
    "ciascuna di esse sono stati eseguiti 10 test. I risultati dei 10 test sono\n",
    "stati poi aggregati prendendo media e deviazione standard dei tempi registrati.\n",
    "\n",
    "Sia per PPGA che per DEAP sono stati misurati sia il tempo d'esecuzione totale,\n",
    "sia il tempo specifico speso in parallelo, che, nel caso di PPGA comprende le\n",
    "fasi di crossover, mutazione e valutazione, mentre per DEAP comprende solo la\n",
    "fase di valutazione.\n",
    "\n",
    "# Analisi PPGA\n",
    "\n",
    "Per prima cosa si vogliono paragonare le prestazioni offerte dalla versione\n",
    "parallela dell'algoritmo rispetto a alla sua versione sequenziale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "ppga_df = pd.read_csv(\"../datasets/ppga_benchmark_32.csv\")\n",
    "ppga_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tempo d'esecuzione\n",
    "\n",
    "Iniziamo con un semplice grafico che riporta l'andamento del tempo d'esecuzione\n",
    "in funzione del diverso numero di worker e su diverse dimensioni dell'input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time(df: pd.DataFrame):\n",
    "    models = df[\"classifier\"].unique()\n",
    "    workers = df[\"workers\"].unique()\n",
    "    population_sizes = df[\"population_size\"].unique()\n",
    "\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(16, 16))\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        for ps in population_sizes:\n",
    "            mask = (df[\"classifier\"] == model) & (df[\"population_size\"] == ps)\n",
    "            axes[i][0].set_title(f\"{model} total execution time\")\n",
    "            axes[i][0].set_xlabel(\"Workers\")\n",
    "            axes[i][0].set_ylabel(\"Time (seconds)\")\n",
    "            axes[i][0].errorbar(\n",
    "                workers,\n",
    "                df[mask][\"time\"].values,\n",
    "                df[mask][\"time_std\"],\n",
    "                label=f\"Population size: {ps}\",\n",
    "            )\n",
    "\n",
    "            axes[i][0].set_xscale(\"log\", base=2)\n",
    "            axes[i][0].set_xticks(workers, labels=[int(2**w) for w in np.log2(workers)])\n",
    "            axes[i][0].grid()\n",
    "            axes[i][0].legend()\n",
    "\n",
    "            axes[i][1].set_title(f\"{model} partial execution time\")\n",
    "            axes[i][1].set_xlabel(\"Workers\")\n",
    "            axes[i][1].set_ylabel(\"Time (seconds)\")\n",
    "            axes[i][1].errorbar(\n",
    "                workers,\n",
    "                df[mask][\"ptime\"].values,\n",
    "                df[mask][\"ptime_std\"],\n",
    "                label=f\"Population size: {ps}\",\n",
    "            )\n",
    "\n",
    "            axes[i][1].set_xscale(\"log\", base=2)\n",
    "            axes[i][1].set_xticks(workers, labels=[int(2**w) for w in np.log2(workers)])\n",
    "            axes[i][1].grid()\n",
    "            axes[i][1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_time(ppga_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed up\n",
    "\n",
    "Procediamo con il calcolare lo _speed up_ ottenuto per ogni modello e per ogni\n",
    "numero di individui sintetici. Anche qui viene calcolato sia lo speed up\n",
    "ottenuto sull'esecuzione dell'intero algoritmo, sia quello ottenuto solo sulla\n",
    "parte parallelizzata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_times = ppga_df[ppga_df[\"workers\"] == 1].set_index(\n",
    "    [\"classifier\", \"population_size\"]\n",
    ")[\"time\"]\n",
    "\n",
    "ppga_df[\"speed_up\"] = ppga_df.apply(\n",
    "    lambda row: reference_times.loc[(row[\"classifier\"], row[\"population_size\"])]\n",
    "    / row[\"time\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "reference_ptimes = ppga_df[ppga_df[\"workers\"] == 1].set_index(\n",
    "    [\"classifier\", \"population_size\"]\n",
    ")[\"ptime\"]\n",
    "\n",
    "ppga_df[\"pure_speed_up\"] = ppga_df.apply(\n",
    "    lambda row: reference_ptimes.loc[(row[\"classifier\"], row[\"population_size\"])]\n",
    "    / row[\"ptime\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "ppga_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di seguito vari grafici per vedere l'andamento dello speed up in relazione\n",
    "al numero di individui sintetici generati.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_speed_up(df: pd.DataFrame):\n",
    "    models = df[\"classifier\"].unique()\n",
    "    workers = df[\"workers\"].unique()\n",
    "    population_sizes = df[\"population_size\"].unique()\n",
    "\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(16, 16))\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        for ps in population_sizes:\n",
    "            mask = (df[\"classifier\"] == model) & (df[\"population_size\"] == ps)\n",
    "            axes[i][0].set_title(f\"{model} speed up\")\n",
    "            axes[i][0].set_xlabel(\"Workers\")\n",
    "            axes[i][0].set_ylabel(\"Speed up\")\n",
    "            axes[i][0].errorbar(\n",
    "                workers,\n",
    "                df[mask][\"speed_up\"].values,\n",
    "                label=f\"Population size: {ps}\",\n",
    "            )\n",
    "\n",
    "            axes[i][0].set_xscale(\"log\", base=2)\n",
    "            axes[i][0].set_xticks(workers, labels=[int(2**w) for w in np.log2(workers)])\n",
    "            axes[i][0].grid()\n",
    "            axes[i][0].legend()\n",
    "\n",
    "            axes[i][1].set_title(f\"{model} pure speed up\")\n",
    "            axes[i][1].set_xlabel(\"Workers\")\n",
    "            axes[i][1].set_ylabel(\"Speed up\")\n",
    "            axes[i][1].errorbar(\n",
    "                workers,\n",
    "                df[mask][\"pure_speed_up\"].values,\n",
    "                label=f\"Population size: {ps}\",\n",
    "            )\n",
    "\n",
    "            axes[i][1].set_xscale(\"log\", base=2)\n",
    "            axes[i][1].set_xticks(workers, labels=[int(2**w) for w in np.log2(workers)])\n",
    "            axes[i][1].grid()\n",
    "            axes[i][1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_speed_up(ppga_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come è facile notare, il Random Forest, che è anche il più lento, è quello che\n",
    "trae più beneficio da una parallelizzazione più pesante. Gli altri modelli\n",
    "sono molto più performanti in fase di predizione ed è quindi più difficile\n",
    "ottenere un valore di speed up vicino al numero di worker utilizzati.\n",
    "\n",
    "## Stabilità\n",
    "\n",
    "Come ultima analisi vorrei valutare la stabilità delle performance\n",
    "dell'algoritmo stesso andando a calcolare il coefficiente di variazione\n",
    "del tempo impiegato. Andiamo quindi a calcolare\n",
    "\n",
    "$$\\frac{\\sigma}{\\mu}$$\n",
    "\n",
    "dove $\\mu$ e $\\sigma$ sono media e deviazione standard dei tempi d'esecuzione\n",
    "ottenuti da 10 prove ripetute dello stesso test. Questo dovrebbe darci indicare\n",
    "approssimativamente quanto sia facile prevedere il tempo d'esecuzione\n",
    "dell'algoritmo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppga_df[\"var_coeff\"] = ppga_df[\"time_std\"] / ppga_df[\"time\"]\n",
    "ppga_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo modo è possibile vedere la stabilità dell'algoritmo al variare di\n",
    "parametri come numero di worker e dimensioni della popolazione. Come soglia\n",
    "per separare i test più stabili dagli altri ho scelto un valore del 10% per\n",
    "il coefficiente di variabilità.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_var_coeff(df: pd.DataFrame):\n",
    "    models = df[\"classifier\"].unique()\n",
    "    workers = np.log2(np.array(df[\"workers\"].unique()))\n",
    "    population_sizes = df[\"population_size\"].unique()\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 18))\n",
    "\n",
    "    for model, ax in zip(models, axes):\n",
    "        ax.plot([-0.5, 5.5], [0.1, 0.1], c=\"r\", label=\"low variability threshold\")\n",
    "        for i, ps in enumerate(population_sizes):\n",
    "            mask = (df[\"classifier\"] == model) & (df[\"population_size\"] == ps)\n",
    "            ax.set_title(f\"{model} execution time variability\")\n",
    "            ax.set_xlabel(\"Workers\")\n",
    "            ax.set_ylabel(\"Variability coefficient\")\n",
    "            ax.bar(\n",
    "                workers + i * 0.105,\n",
    "                df[mask][\"var_coeff\"].values,\n",
    "                width=0.1,\n",
    "                label=f\"Population size: {ps}\",\n",
    "            )\n",
    "\n",
    "            ax.set_xticks(workers, labels=[int(2**w) for w in workers])\n",
    "            ax.grid()\n",
    "            ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_var_coeff(ppga_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dai test effettuati sembra che al variare del numero di worker e della\n",
    "dimensione della popolazione il coefficiente di variabilità sia sempre sotto\n",
    "il 10%.\n",
    "\n",
    "# Analisi DEAP con multiprocessing\n",
    "\n",
    "Il modulo DEAP offre due metodi per parallelizzare l'algoritmo genetico, il\n",
    "primo tramite il modulo `multiprocessing` e il secondo tramite `scoop`. Di\n",
    "seguito un'analisi della versione tramite `multiprocessing`. Le analisi sono\n",
    "perfettamente analoghe alle precedenti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deap_df = pd.read_csv(\"../datasets/deap_mp_MLPClassifier_32.csv\")\n",
    "deap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tempo d'esecuzione\n",
    "\n",
    "Come prima, alcuni plot rappresentati dell'andamento del tempo d'esecuzione in\n",
    "funzione del diverso numero di worker e su diverse dimensioni dell'input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time(deap_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed up\n",
    "\n",
    "Come prima andiamo ad analizzare lo speed up ottenuto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reference_times = deap_df[deap_df[\"workers\"] == 1].set_index(\n",
    "    [\"classifier\", \"population_size\"]\n",
    ")[\"time\"]\n",
    "\n",
    "deap_df[\"speed_up\"] = deap_df.apply(\n",
    "    lambda row: reference_times.loc[(row[\"classifier\"], row[\"population_size\"])]\n",
    "    / row[\"time\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# reference_ptimes = deap_df[deap_df[\"workers\"] == 1].set_index(\n",
    "#     [\"classifier\", \"population_size\"]\n",
    "# )[\"ptime\"]\n",
    "\n",
    "# deap_df[\"pure_speed_up\"] = deap_df.apply(\n",
    "#     lambda row: reference_ptimes.loc[(row[\"classifier\"], row[\"population_size\"])]\n",
    "#     / row[\"ptime\"],\n",
    "#     axis=1,\n",
    "# )\n",
    "\n",
    "deap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notiamo, sia dalla tabella che dal grafico di seguito, che lo speed up tramite\n",
    "il modulo multiprocessing è generalmente migliore rispetto all'altro algoritmo.\n",
    "Questo probabilmente dovuto a tecniche di bilanciamento del carico e di\n",
    "comunicazione più avanzate. Il confronto vero e proprio sarà fatto di seguito.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_speed_up(deap_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stabilità\n",
    "\n",
    "Come in precedenza andiamo a calcolare il coefficiente di variabilità\n",
    "dell'algoritmo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deap_df[\"var_coeff\"] = deap_df[\"time_std\"] / deap_df[\"time\"]\n",
    "deap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A differenza del caso precedente è possibile, anche solo visivamente, notare\n",
    "una maggiore variabilità nei tempi di esecuzione, soprattutto nel caso della\n",
    "SVM e del MultiLayer Perceptron.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_var_coeff(deap_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confronto con DEAP\n",
    "\n",
    "Passiamo a confrontare le prestazioni con la libreria DEAP. Procederemo\n",
    "confrontando tre parametri:\n",
    "\n",
    "- Tempo d'esecuzione\n",
    "- Speed up\n",
    "- Coefficiente di speed up\n",
    "\n",
    "L'ultimo è un parametro che ci permette di paragonare lo speed up in modo\n",
    "proporzionale tra i due algoritmi che possono aver ottenuto tempi d'esecuzione\n",
    "differenti.\n",
    "\n",
    "## Tempo d'esecuzione\n",
    "\n",
    "Il primo confronto è semplicemente sul tempo d'esecuzione puro dei due\n",
    "algoritmi:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cmp = pd.DataFrame(\n",
    "    {\n",
    "        \"classifier\": ppga_df[\"classifier\"].values,\n",
    "        \"population_size\": ppga_df[\"population_size\"].values,\n",
    "        \"workers\": ppga_df[\"workers\"].values,\n",
    "        \"ppga\": ppga_df[\"time\"].values,\n",
    "        \"deap\": deap_df[\"time\"].values,\n",
    "    }\n",
    ")\n",
    "\n",
    "time_cmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come possiamo vedere dai grafici di seguito sembra che DEAP sia leggermente\n",
    "più lento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_diff(df):\n",
    "    models = df[\"classifier\"].unique()\n",
    "    workers = np.log2(df[\"workers\"].unique())\n",
    "    population_sizes = df[\"population_size\"].unique()\n",
    "\n",
    "    fig, axes = plt.subplots(len(population_sizes), len(models), figsize=(12, 18))\n",
    "\n",
    "    for i, ps in enumerate(population_sizes):\n",
    "        for j, model in enumerate(models):\n",
    "            mask = (df[\"classifier\"] == model) & (df[\"population_size\"] == ps)\n",
    "            axes[i][j].set_title(f\"{model} execution time\\nPopulation size {ps}\")\n",
    "            axes[i][j].set_xlabel(\"Workers\")\n",
    "            axes[i][j].set_ylabel(\"Time (seconds)\")\n",
    "            axes[i][j].bar(\n",
    "                workers - 0.11, df[mask][\"ppga\"].values, width=0.2, label=\"ppga\"\n",
    "            )\n",
    "            axes[i][j].bar(\n",
    "                workers + 0.11, df[mask][\"deap\"].values, width=0.2, label=\"deap\"\n",
    "            )\n",
    "\n",
    "            axes[i][j].set_xticks(workers, labels=[int(2**i) for i in workers])\n",
    "            axes[i][j].legend()\n",
    "            axes[i][j].grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_time_diff(time_cmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di seguito un confronto tra il numero di volte in cui `ppga` ha offerto\n",
    "performance migliori rispetto a DEAP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppga_better_time = time_cmp[time_cmp[\"ppga\"] < time_cmp[\"deap\"]]\n",
    "print(\n",
    "    f\"ppga better than deap {len(ppga_better_time) / len(time_cmp) * 100.0:.2f}% of the times\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andiamo a vedere i valori minimi, medi e massimi dell'aumento di performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improvement = (\n",
    "    (ppga_better_time[\"deap\"] - ppga_better_time[\"ppga\"])\n",
    "    / ppga_better_time[\"deap\"]\n",
    "    * 100.0\n",
    ")\n",
    "print(f\"minimum improvement: {improvement.min():.2f}%\")\n",
    "print(f\"mean improvement: {improvement.mean():.2f}%\")\n",
    "print(f\"max improvement: {improvement.max():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come vediamo `ppga` è tendenzialmente più veloce, mediamente del 20%.\n",
    "\n",
    "Ripetiamo la stessa analisi ma considerando solo i casi in cui DEAP ha fornito\n",
    "le performance migliori.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deap_better_time = time_cmp[time_cmp[\"deap\"] < time_cmp[\"ppga\"]]\n",
    "print(\n",
    "    f\"deap better than ppga {len(deap_better_time) / len(time_cmp) * 100.0:.2f}% of the times\"\n",
    ")\n",
    "\n",
    "improvement = (\n",
    "    (deap_better_time[\"ppga\"] - deap_better_time[\"deap\"])\n",
    "    / deap_better_time[\"ppga\"]\n",
    "    * 100.0\n",
    ")\n",
    "print(f\"minimum improvement: {improvement.min():.2f}%\")\n",
    "print(f\"mean improvement: {improvement.mean():.2f}%\")\n",
    "print(f\"max improvement: {improvement.max():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non sembrano esserci grandi differenze per quanto riguarda i valori minimi e\n",
    "medi, ma è stato registrato almeno un caso in cui DEAP ha fornito performance\n",
    "migliori del 50% rispetto a PPGA.\n",
    "\n",
    "## Speed up\n",
    "\n",
    "Passiamo ora al confronto dello speed up tra i due algoritmi. Le analisi saranno\n",
    "analoghe a quelle fatte per il tempo d'esecuzione.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup_cmp = pd.DataFrame(\n",
    "    {\n",
    "        \"classifier\": ppga_df[\"classifier\"].values,\n",
    "        \"population_size\": ppga_df[\"population_size\"].values,\n",
    "        \"workers\": ppga_df[\"workers\"].values,\n",
    "        \"ppga\": ppga_df[\"speed_up\"].values,\n",
    "        \"deap\": deap_df[\"speed_up\"].values,\n",
    "    }\n",
    ")\n",
    "\n",
    "speedup_cmp = speedup_cmp[speedup_cmp[\"workers\"] != 1]\n",
    "speedup_cmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stavolta sembra che DEAP abbia valori di speed up migliori, come si può notare\n",
    "dai grafici riportati di seguito.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_diff(df):\n",
    "    models = df[\"classifier\"].unique()\n",
    "    workers = np.log2(df[\"workers\"].unique())\n",
    "    population_sizes = df[\"population_size\"].unique()\n",
    "\n",
    "    fig, axes = plt.subplots(len(population_sizes), len(models), figsize=(12, 18))\n",
    "\n",
    "    for i, ps in enumerate(population_sizes):\n",
    "        for j, model in enumerate(models):\n",
    "            mask = (df[\"classifier\"] == model) & (df[\"population_size\"] == ps)\n",
    "            axes[i][j].set_title(f\"{model} speed up\\nPopulation size {ps}\")\n",
    "            axes[i][j].set_xlabel(\"Workers\")\n",
    "            axes[i][j].set_ylabel(\"Speed up\")\n",
    "            axes[i][j].bar(\n",
    "                workers - 0.11, df[mask][\"ppga\"].values, width=0.2, label=\"ppga\"\n",
    "            )\n",
    "            axes[i][j].bar(\n",
    "                workers + 0.11, df[mask][\"deap\"].values, width=0.2, label=\"deap\"\n",
    "            )\n",
    "\n",
    "            axes[i][j].set_xticks(workers, labels=[int(2**i) for i in workers])\n",
    "            axes[i][j].legend()\n",
    "            axes[i][j].grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_time_diff(speedup_cmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andiamo però a vedere quante volte DEAP è stato migliore di PPGA come abbiamo\n",
    "fatto in precedenza.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppga_better_speedup = speedup_cmp[speedup_cmp[\"ppga\"] > speedup_cmp[\"deap\"]]\n",
    "print(\n",
    "    f\"ppga better than deap {len(ppga_better_speedup) / len(speedup_cmp) * 100.0:.2f}% of the times\"\n",
    ")\n",
    "\n",
    "improvement = (\n",
    "    (ppga_better_speedup[\"ppga\"] - ppga_better_speedup[\"deap\"])\n",
    "    / ppga_better_speedup[\"deap\"]\n",
    "    * 100.0\n",
    ")\n",
    "print(f\"minimum improvement: {improvement.min():.2f}%\")\n",
    "print(f\"mean improvement: {improvement.mean():.2f}%\")\n",
    "print(f\"max improvement: {improvement.max():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deap_better_speedup = speedup_cmp[speedup_cmp[\"deap\"] > speedup_cmp[\"ppga\"]]\n",
    "print(\n",
    "    f\"deap better than ppga {len(deap_better_speedup) / len(speedup_cmp) * 100.0:.2f}% of the times\"\n",
    ")\n",
    "\n",
    "improvement = (\n",
    "    (deap_better_speedup[\"deap\"] - deap_better_speedup[\"ppga\"])\n",
    "    / deap_better_speedup[\"ppga\"]\n",
    "    * 100.0\n",
    ")\n",
    "print(f\"minimum improvement: {improvement.min():.2f}%\")\n",
    "print(f\"mean improvement: {improvement.mean():.2f}%\")\n",
    "print(f\"max improvement: {improvement.max():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo caso DEAP risulta avere i migliori valori di speed la maggior parte\n",
    "delle volte.\n",
    "\n",
    "## Coefficiente di speed up\n",
    "\n",
    "Confrontare il tempo d'esecuzione può essere un buon indice per paragonare le\n",
    "performance di un algoritmo, quando però andiamo a paragonare i valori di speed\n",
    "up non otteniamo una vera e propria misura di quanto un modello di calcolo\n",
    "parallelo sia migliore rispetto ad un altro. Questo è anche dovuto al fatto\n",
    "che il tempo d'esecuzione, a parità di worker impiegati, potrebbe variare.\n",
    "Diventa quindi necessario ricavare una misura che sia proporzionale al tempo\n",
    "d'esecuzione. Di seguito viene calcolato un \"coefficiente di speed up\"\n",
    "\n",
    "$$\\frac{s}{t}$$\n",
    "\n",
    "dove $s$ è lo speed up ottenuto e $t$ il tempo totale d'esecuzione.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup_coeff_cmp = pd.DataFrame(\n",
    "    {\n",
    "        \"classifier\": ppga_df[\"classifier\"].values,\n",
    "        \"population_size\": ppga_df[\"population_size\"].values,\n",
    "        \"workers\": ppga_df[\"workers\"].values,\n",
    "        \"ppga\": (ppga_df[\"speed_up\"] / ppga_df[\"time\"]).values,\n",
    "        \"deap\": (deap_df[\"speed_up\"] / deap_df[\"time\"]).values,\n",
    "    }\n",
    ")\n",
    "\n",
    "speedup_coeff_cmp = speedup_coeff_cmp[speedup_coeff_cmp[\"workers\"] != 1]\n",
    "speedup_coeff_cmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalla tabella e dai grafici riportati di seguito possiamo notare come PPGA\n",
    "offra, nella maggior parte dei casi, un coefficiente migliore.\n",
    "\n",
    "Dobbiamo però considerare anche l'andamento di tale coefficiente caso per caso.\n",
    "Se rimane stabile o tende a crescere con il crescere del numero di worker,\n",
    "potrebbe essere un buon indice per valutare la scalabilità dell'algoritmo\n",
    "su un numero ancora più alto di worker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_diff(df):\n",
    "    models = df[\"classifier\"].unique()\n",
    "    workers = np.log2(df[\"workers\"].unique())\n",
    "    population_sizes = df[\"population_size\"].unique()\n",
    "\n",
    "    fig, axes = plt.subplots(len(population_sizes), len(models), figsize=(12, 18))\n",
    "\n",
    "    for i, ps in enumerate(population_sizes):\n",
    "        for j, model in enumerate(models):\n",
    "            mask = (df[\"classifier\"] == model) & (df[\"population_size\"] == ps)\n",
    "            axes[i][j].set_title(f\"{model} speed up\\nPopulation size {ps}\")\n",
    "            axes[i][j].set_xlabel(\"Workers\")\n",
    "            axes[i][j].set_ylabel(\"Speed up coefficient\")\n",
    "            axes[i][j].bar(\n",
    "                workers - 0.11, df[mask][\"ppga\"].values, width=0.2, label=\"ppga\"\n",
    "            )\n",
    "            axes[i][j].bar(\n",
    "                workers + 0.11, df[mask][\"deap\"].values, width=0.2, label=\"deap\"\n",
    "            )\n",
    "\n",
    "            axes[i][j].set_xticks(workers, labels=[int(2**i) for i in workers])\n",
    "            axes[i][j].legend()\n",
    "            axes[i][j].grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_time_diff(speedup_coeff_cmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come già detto, il coefficiente vuole essere un indice di quanto l'algoritmo\n",
    "scala bene con il crescere del numero di worker. Come possiamo vedere, una\n",
    "casistica in cui il carico dei singoli worker tende ad essere leggero, un\n",
    "approccio in cui c'è un bilanciamento automatico e dinamico del carico di lavoro\n",
    "risulta essere vincente sia in termini di tempo d'esecuzione, sia in termini di\n",
    "utilizzo delle risorse fornite (in questo caso i core multipli della macchina).\n",
    "\n",
    "Quando però il workload si fa più intenso, sembra essere più vantaggioso\n",
    "partizionare subito l'input e lasciare lavorare i worker senza ulteriori\n",
    "overhead di sincronizzazione e comunicazione.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppga_better_coeff = speedup_coeff_cmp[\n",
    "    speedup_coeff_cmp[\"ppga\"] > speedup_coeff_cmp[\"deap\"]\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"deap better than ppga {len(ppga_better_coeff) / len(speedup_coeff_cmp) * 100.0:.2f}% of the times\"\n",
    ")\n",
    "\n",
    "improvement = (\n",
    "    (ppga_better_coeff[\"ppga\"] - ppga_better_coeff[\"deap\"])\n",
    "    / ppga_better_coeff[\"deap\"]\n",
    "    * 100.0\n",
    ")\n",
    "print(f\"minimum improvement: {improvement.min():.2f}%\")\n",
    "print(f\"mean improvement: {improvement.mean():.2f}%\")\n",
    "print(f\"max improvement: {improvement.max():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deap_better_coeff = speedup_coeff_cmp[\n",
    "    speedup_coeff_cmp[\"deap\"] > speedup_coeff_cmp[\"ppga\"]\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"deap better than ppga {len(deap_better_coeff) / len(speedup_coeff_cmp) * 100.0:.2f}% of the times\"\n",
    ")\n",
    "\n",
    "improvement = (\n",
    "    (deap_better_coeff[\"deap\"] - deap_better_coeff[\"ppga\"])\n",
    "    / deap_better_coeff[\"ppga\"]\n",
    "    * 100.0\n",
    ")\n",
    "print(f\"minimum improvement: {improvement.min():.2f}%\")\n",
    "print(f\"mean improvement: {improvement.mean():.2f}%\")\n",
    "print(f\"max improvement: {improvement.max():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusioni\n",
    "\n",
    "In quanto a tempo d'esecuzione sembra prevalere PPGA con un buon 80% dei test\n",
    "eseguiti con un tempo inferiore a DEAP. Di questo 80% c'è un miglioramento\n",
    "medio del 20% e un miglioramento massimo del 40%.\n",
    "\n",
    "Sui valori di speed up delle versioni parallele DEAP riesce in diversi casi a\n",
    "sfruttare meglio le risorse computazionali a disposizione. La differenza tende\n",
    "però ad appianarsi quando il carico di lavoro di ogni worker si fa sempre più\n",
    "grande.\n",
    "\n",
    "Per l'ultimo coefficiente valgono più o meno le stesse considerazioni fatte\n",
    "sullo speed up. Come si nota dai grafici, i casi in cui il coefficiente è più\n",
    "alto per PPGA sono quelli con pochi worker, che dunque saranno più carichi\n",
    "di lavoro. Qui diventa determinate il tempo d'esecuzione, tendenzialmente\n",
    "inferiore, di PPGA.\n",
    "\n",
    "Se però entrano in gioco un alto numero di worker e workload eterogenei, la\n",
    "miglior scelta ricade sul `multiprocessing.Pool` utilizzato da DEAP.\n",
    "\n",
    "## Considerazioni parallelismo\n",
    "\n",
    "Prima di concludere vorrei evidenziare alcune possibili criticità quando si\n",
    "lavora con la versione parallela di PPGA, prendendo sempre come riferimento il\n",
    "solito problema. A differenza di DEAP, che parallelizza solo la fase di\n",
    "valutazione, PPGA parallelizza anche le fasi di crossover, mutazione.\n",
    "\n",
    "Durante la fase di test sono emersi alcuni problemi, anche se in un sottoinsieme\n",
    "ridotto di casistiche, che hanno portato alla luce alcuni fattori a cui fare\n",
    "attenzione.\n",
    "\n",
    "Dato che la genereazione della popolazione iniziale avviene per copia, la\n",
    "diversità genetica iniziale è pari a zero. Per un algoritmo genetico, questo\n",
    "è in generale un problema dato che sfrutta meccanismi come il crossover per\n",
    "ricombinare i cromosomi tra individui diversi.\n",
    "\n",
    "Nel nostro caso partiamo però da una situazione in cui tutti gli individui sono\n",
    "cloni e utilizziamo metodi di crossover come il crossover singolo o doppio, il\n",
    "quale ricombina le feature tra due cromosomi senza però alterare il loro ordine.\n",
    "\n",
    "Ne segue che l'applicazione del crossover tra due cloni risulterà nella\n",
    "generazione di altri due cloni identici tra di loro e ai loro genitori. Per le\n",
    "prime iterazioni ci si affida quindi all'operatore di mutazione come unico\n",
    "meccanismo per introdurre diversità genetica.\n",
    "\n",
    "Il problema è che la mutazione ha generalmente una probabilità bassa di essere\n",
    "applicata (in genere 20/30%). Se aggiungiamo poi che ogni feature ha una\n",
    "probabilità indipendente di essere modificata, la probabilità che un individuo\n",
    "venga effettivamente modificato cala ulteriormente.\n",
    "\n",
    "Aggiungiamo infine che quando partizioniamo la popolazione tra molti worker si\n",
    "potrebbe andare incontro ad un problema nel caso in cui il rapporto\n",
    "\n",
    "$$\\frac{N}{W}$$\n",
    "\n",
    "dove $N$ è il numero di individui e $W$ è il numero di worker, è troppo basso.\n",
    "Si rischia che i worker mutino pochi individui o nessuno, lasciando la\n",
    "diversità genetica bassa per diverse iterazioni.\n",
    "\n",
    "Per evitare che succeda c'è bisogno che la probabilità indipendente di\n",
    "modificare ogni feature faccia sì che mediamente, almeno una feature venga\n",
    "modificata. Per esempio ponendola a $1 / L$ dove $L$ è la lunghezza del\n",
    "cromosoma.\n",
    "\n",
    "In secondo luogo è necessario che il numero di individui inviato ad ogni worker\n",
    "sia abbastanza grande da \"garantire\" un certo numero di individui mutati.\n",
    "\n",
    "Ultima considerazione che potrebbe essere banale è impostare manualmente il\n",
    "_seed_ dei generatori pseudocasuali di ogni worker, altrimenti inizializzato\n",
    "con l'orologio ad una risoluzione dell'ordine dei secondi.\n",
    "\n",
    "Ne seguirebbe che ogni worker è inizializzato quasi sicuramente con lo stesso\n",
    "seed e quindi muta gli stessi individui allo stesso modo degli altri worker.\n",
    "Andiamo quindi a creare $W$ sottopopolazioni tutte identiche tra di loro.\n",
    "\n",
    "## Ulteriore strategia di parallelizzazione\n",
    "\n",
    "Nel problema di explainability in cui si richiedono numerose esecuzioni\n",
    "dell'algoritmo genetico, si potrebbe pensare di partizionare il dataset in $m$\n",
    "parti e adibire $n$ core a ciascuna partizione di modo da eseguire l'algoritmo\n",
    "genetico parallelo su $n$ core e su $m$ punti contemporaneamente. Ovviamente\n",
    "è necessaria un'analisi preliminare in cui si cerca di approssimare il numero\n",
    "di worker più adatto ad una singola esecuzione dell'algoritmo genetico. Il\n",
    "numero di partizioni del dataset sarà semplicemente calcolato come:\n",
    "\n",
    "$$\\frac{ct}{w}$$\n",
    "\n",
    "dove $ct$ è il numero di core totali presenti sulla macchina o che si intende\n",
    "utilizzare e $w$ è il numero di worker stimato al passo precedente.\n"
   ]
  }
 ],
 "metadata": {
  "@deathbeds/jupyterlab-fonts": {
   "styles": {
    ":root": {
     "--jp-code-font-size": "18px",
     "--jp-content-font-size1": "18px"
    }
   }
  },
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
